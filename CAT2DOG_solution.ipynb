{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAT2DOG.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNWPlLtrEG3NZxtaqCI4P3F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ylongresearch/COMP4107-ACV/blob/main/CAT2DOG_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3y7TJd4nxX3d",
        "outputId": "c4b4d9f3-14df-42fe-e584-638b9d582f41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We're using => cuda\n",
            "Thu Mar  3 13:16:06 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    34W / 250W |   1127MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"We're using =>\", device)\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "print(X_train.shape, X_train.dtype, Y_train.shape, Y_train.dtype)\n",
        "#########################\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "cat_idx = np.where(Y_train[:, 0] == 3)\n",
        "dog_idx = np.where(Y_train[:, 0] == 5)\n",
        "cat_idx_test = np.where(Y_test[:, 0] == 3)\n",
        "dog_idx_test = np.where(Y_test[:, 0] == 5)\n",
        "\n",
        "print(np.shape(cat_idx))\n",
        "print(np.shape(dog_idx))\n",
        "plt.imshow(X_train[dog_idx[0][4999]]) # visualise random images in range 0 to 4999\n",
        "################################\n",
        "\n",
        "cat_dog_idx = np.concatenate((cat_idx[0], dog_idx[0]))\n",
        "cat_dog_idx_test = np.concatenate((cat_idx_test[0], dog_idx_test[0]))\n",
        "\n",
        "cat_train = X_train[cat_idx]\n",
        "dog_train = X_train[dog_idx]\n",
        "cat_test = X_test[cat_idx_test]\n",
        "dog_test = X_test[dog_idx_test]\n",
        "\n",
        "\n",
        "cat_train = np.transpose(cat_train, (0,3,2,1))\n",
        "dog_train = np.transpose(dog_train, (0,3,2,1))\n",
        "cat_test = np.transpose(cat_test, (0,3,2,1))\n",
        "dog_test = np.transpose(dog_test, (0,3,2,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "tN-HFL4T2wcT",
        "outputId": "09f037eb-c363-48b5-d4e2-bb29d276b5d9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3) uint8 (50000, 1) uint8\n",
            "(1, 5000)\n",
            "(1, 5000)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations==0.4.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCs4CsSu3fYX",
        "outputId": "f6ada31a-b164-411a-edd4-4af6abd5b9c6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations==0.4.6 in /usr/local/lib/python3.7/dist-packages (0.4.6)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n",
            "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (0.4.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.1.post1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "transforms = A.Compose(\n",
        "    [\n",
        "        #A.Resize(width=256, height=256),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),\n",
        "        ToTensorV2(),\n",
        "     ],\n",
        "    additional_targets={\"image0\": \"image\"},\n",
        ")\n",
        "\n",
        "class PBdataset(Dataset):\n",
        "    def __init__(self, X, Y, transform = None):\n",
        "\n",
        "        self.X = torch.from_numpy(X)/255\n",
        "\n",
        "        self.Y = torch.from_numpy(Y)/255\n",
        "        # self.X = X\n",
        "        # self.X = Y\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # X = self.transform(self.X[index])\n",
        "        # Y = self.transform(self.Y[index])\n",
        "        return self.X[index], self.Y[index]   # self.Y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "\n",
        "batch_size = 50\n",
        "catdogTrainSet = PBdataset(cat_train,dog_train,transform=transforms)\n",
        "catdogTrainLoader = torch.utils.data.DataLoader(catdogTrainSet, batch_size=batch_size, shuffle=True)\n",
        "catdogTestSet = PBdataset(cat_test,dog_test,transform=transforms)\n",
        "catdogTestLoader = torch.utils.data.DataLoader(catdogTestSet, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "lZSqFwaO3LIN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, down=True, use_act=True, **kwargs):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, padding_mode=\"reflect\", **kwargs)\n",
        "            if down\n",
        "            else nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True) if use_act else nn.Identity()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            ConvBlock(channels, channels, kernel_size=3, padding=1),\n",
        "            ConvBlock(channels, channels, use_act=False, kernel_size=3, padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, img_channels, num_features = 16, num_residuals=3):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(img_channels, num_features, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\"),\n",
        "            nn.InstanceNorm2d(num_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.down_blocks = nn.ModuleList(\n",
        "            [\n",
        "                ConvBlock(num_features, num_features*2, kernel_size=3, stride=2, padding=1),\n",
        "                ConvBlock(num_features*2, num_features*4, kernel_size=3, stride=2, padding=1),\n",
        "            ]\n",
        "        )\n",
        "        self.res_blocks = nn.Sequential(\n",
        "            *[ResidualBlock(num_features*4) for _ in range(num_residuals)]\n",
        "        )\n",
        "        self.up_blocks = nn.ModuleList(\n",
        "            [\n",
        "                ConvBlock(num_features*4, num_features*2, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "                ConvBlock(num_features*2, num_features*1, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.last = nn.Conv2d(num_features*1, img_channels, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial(x)\n",
        "        for layer in self.down_blocks:\n",
        "            x = layer(x)\n",
        "        x = self.res_blocks(x)\n",
        "        for layer in self.up_blocks:\n",
        "            x = layer(x)\n",
        "        return torch.tanh(self.last(x))\n",
        "\n",
        "\n",
        "img_channels = 3\n",
        "img_size = 30\n",
        "x = torch.randn((12, img_channels, img_size, img_size))\n",
        "gen = Generator(img_channels, 3)\n",
        "print(gen(x).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QtnDU5Q4Gb_",
        "outputId": "030998b5-c09a-4b8f-b137-ce6fba85a494"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([12, 3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 4, stride, 1, bias=True, padding_mode=\"reflect\"),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3, features=[32, 64]):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels,\n",
        "                features[0],\n",
        "                kernel_size=4,\n",
        "                stride=2,\n",
        "                padding=1,\n",
        "                padding_mode=\"reflect\",\n",
        "            ),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        layers = []\n",
        "        in_channels = features[0]\n",
        "        for feature in features[1:]:\n",
        "            layers.append(Block(in_channels, feature, stride=1 if feature==features[-1] else 2))\n",
        "            in_channels = feature\n",
        "        layers.append(nn.Conv2d(in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"))\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial(x)\n",
        "        return torch.sigmoid(self.model(x))\n",
        "\n",
        "x = torch.randn((5, 3, 30, 30))\n",
        "model = Discriminator(in_channels=3)\n",
        "preds = model(x)\n",
        "print(preds.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riIdPkBI4QTo",
        "outputId": "b84c652e-146b-481a-f7ab-7f065dc664e5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 1, 13, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "LEARNING_RATE = 1e-5\n",
        "LAMBDA_IDENTITY = 0.0\n",
        "LAMBDA_CYCLE = 10\n",
        "NUM_EPOCHS = 10\n",
        "SAVE_MODEL = False\n",
        "def train_fn(disc_H, disc_Z, gen_Z, gen_H, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler):\n",
        "    H_reals = 0\n",
        "    H_fakes = 0\n",
        "    loop = tqdm(loader, leave=True)\n",
        "\n",
        "    for idx, (cat, dog) in enumerate(loop):\n",
        "        cat = cat.to(device)\n",
        "        dog = dog.to(device)\n",
        "\n",
        "        # Train Discriminators H and Z\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake_dog = gen_H(cat)\n",
        "            D_H_real = disc_H(dog)\n",
        "            D_H_fake = disc_H(fake_dog.detach())\n",
        "            H_reals += D_H_real.mean().item()\n",
        "            H_fakes += D_H_fake.mean().item()\n",
        "            D_H_real_loss = mse(D_H_real, torch.ones_like(D_H_real))\n",
        "            D_H_fake_loss = mse(D_H_fake, torch.zeros_like(D_H_fake))\n",
        "            D_H_loss = D_H_real_loss + D_H_fake_loss\n",
        "\n",
        "            fake_cat = gen_Z(dog)\n",
        "            D_Z_real = disc_Z(cat)\n",
        "            D_Z_fake = disc_Z(fake_cat.detach())\n",
        "            D_Z_real_loss = mse(D_Z_real, torch.ones_like(D_Z_real))\n",
        "            D_Z_fake_loss = mse(D_Z_fake, torch.zeros_like(D_Z_fake))\n",
        "            D_Z_loss = D_Z_real_loss + D_Z_fake_loss\n",
        "\n",
        "            # put it togethor\n",
        "            D_loss = (D_H_loss + D_Z_loss)/2\n",
        "\n",
        "        opt_disc.zero_grad()\n",
        "        d_scaler.scale(D_loss).backward()\n",
        "        d_scaler.step(opt_disc)\n",
        "        d_scaler.update()\n",
        "\n",
        "        # Train Generators H and Z\n",
        "        with torch.cuda.amp.autocast():\n",
        "            # adversarial loss for both generators\n",
        "            D_H_fake = disc_H(fake_dog)\n",
        "            D_Z_fake = disc_Z(fake_cat)\n",
        "            loss_G_H = mse(D_H_fake, torch.ones_like(D_H_fake))\n",
        "            loss_G_Z = mse(D_Z_fake, torch.ones_like(D_Z_fake))\n",
        "\n",
        "            # cycle loss\n",
        "            cycle_cat = gen_Z(fake_dog)\n",
        "            cycle_dog = gen_H(fake_cat)\n",
        "            cycle_cat_loss = l1(cat, cycle_cat)\n",
        "            cycle_dog_loss = l1(dog, cycle_dog)\n",
        "\n",
        "            # identity loss (remove these for efficiency if you set lambda_identity=0)\n",
        "            identity_cat = gen_Z(cat)\n",
        "            identity_dog = gen_H(dog)\n",
        "            identity_cat_loss = l1(cat, identity_cat)\n",
        "            identity_dog_loss = l1(dog, identity_dog)\n",
        "\n",
        "            # add all togethor\n",
        "            G_loss = (\n",
        "                loss_G_Z\n",
        "                + loss_G_H\n",
        "                + cycle_cat_loss * LAMBDA_CYCLE\n",
        "                + cycle_dog_loss * LAMBDA_CYCLE\n",
        "                + identity_dog_loss * LAMBDA_IDENTITY\n",
        "                + identity_cat_loss * LAMBDA_IDENTITY\n",
        "            )\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        g_scaler.scale(G_loss).backward()\n",
        "        g_scaler.step(opt_gen)\n",
        "        g_scaler.update()\n",
        "\n",
        "        if idx % 20 == 0:\n",
        "            save_image(fake_dog*0.5+0.5, f\"./saved_images/dog_{idx}.png\")\n",
        "            save_image(fake_cat*0.5+0.5, f\"./saved_images/cat_{idx}.png\")\n",
        "\n",
        "        loop.set_postfix(H_real=H_reals/(idx+1), H_fake=H_fakes/(idx+1))"
      ],
      "metadata": {
        "id": "m10hIV2G4aCf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir saved_images"
      ],
      "metadata": {
        "id": "yIQSMRvn5A39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c5a6af3-f237-4125-848e-9931cb310f1d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘saved_images’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    disc_H = Discriminator(in_channels=3).to(device)\n",
        "    disc_Z = Discriminator(in_channels=3).to(device)\n",
        "    gen_Z = Generator(img_channels=3, num_residuals=4).to(device)\n",
        "    gen_H = Generator(img_channels=3, num_residuals=4).to(device)\n",
        "    opt_disc = optim.Adam(\n",
        "        list(disc_H.parameters()) + list(disc_Z.parameters()),\n",
        "        lr=LEARNING_RATE,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "    opt_gen = optim.Adam(\n",
        "        list(gen_Z.parameters()) + list(gen_H.parameters()),\n",
        "        lr=LEARNING_RATE,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "    L1 = nn.L1Loss()\n",
        "    mse = nn.MSELoss()\n",
        "\n",
        "\n",
        "    g_scaler = torch.cuda.amp.GradScaler()\n",
        "    d_scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        train_fn(disc_H, disc_Z, gen_Z, gen_H, catdogTrainLoader, opt_disc, opt_gen, L1, mse, d_scaler, g_scaler)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "KVvmwAWz4oX2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ffa0345-5075-49b1-e999-4289cac9e588"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:14<00:00,  6.96it/s, H_fake=0.49, H_real=0.49]\n",
            "100%|██████████| 100/100 [00:11<00:00,  8.50it/s, H_fake=0.496, H_real=0.506]\n",
            "100%|██████████| 100/100 [00:11<00:00,  8.49it/s, H_fake=0.492, H_real=0.51]\n",
            "100%|██████████| 100/100 [00:11<00:00,  8.35it/s, H_fake=0.488, H_real=0.512]\n",
            "100%|██████████| 100/100 [00:11<00:00,  8.48it/s, H_fake=0.485, H_real=0.515]\n",
            "100%|██████████| 100/100 [00:11<00:00,  8.49it/s, H_fake=0.482, H_real=0.517]\n",
            "100%|██████████| 100/100 [00:11<00:00,  8.51it/s, H_fake=0.479, H_real=0.519]\n",
            "100%|██████████| 100/100 [00:11<00:00,  8.52it/s, H_fake=0.476, H_real=0.521]\n",
            "100%|██████████| 100/100 [00:12<00:00,  8.32it/s, H_fake=0.474, H_real=0.523]\n",
            "100%|██████████| 100/100 [00:11<00:00,  8.52it/s, H_fake=0.473, H_real=0.524]\n"
          ]
        }
      ]
    }
  ]
}